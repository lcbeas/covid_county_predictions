{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import timedelta\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users just change this part of the code:\n",
    "# num_days = how many days from today do you want to predict \n",
    "# prediction_file_name = csv file that will be created with just states, counties, prediction\n",
    "# jhu_and_prediction_file_name = csv file that will be created with entire jhu data and predictions appended on the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days = 10\n",
    "prediction_file_name = 'v2_pred_10days_from05222020.csv'\n",
    "jhu_and_prediciton_file_name = 'v2_full_pred_10days_from05222020.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "jhu_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
    "jhu = pd.read_csv(jhu_url)\n",
    "first_case_day = jhu.replace(0, np.nan).iloc[:, 11:].apply(lambda series: series.first_valid_index(), axis = 1)\n",
    "first_day = pd.to_datetime('1/22/20')\n",
    "def conv_delta_to_int (dt):\n",
    "    return int(str(dt).split(\" \")[0])\n",
    "conv_to_int = np.vectorize(conv_delta_to_int)\n",
    "first_cases = pd.to_datetime(first_case_day)\n",
    "first_cases= first_cases.fillna(pd.datetime.now())\n",
    "first_cases = conv_to_int(pd.to_datetime(first_cases) - first_day)\n",
    "jhu.insert(2, 'first_case_day', first_cases)\n",
    "\n",
    "numeric_cols = [col for col in jhu if jhu[col].dtype.kind != 'O']\n",
    "cols = numeric_cols[5:]\n",
    "jhu[cols] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decline_day = 75  # what day should we start looking for a decline\n",
    "days_of_decline = 7 # how many days of decline in the range (decline day to today) will trigger a model that is declining\n",
    "val_set_size = 1\n",
    "\n",
    "epochs = 5 # how many times does scipy.optimize run each time - only local maximum so running multiple times and taking best\n",
    "first_day_column = jhu.columns.get_loc(\"1/22/20\")\n",
    "def conv_delta_to_int (dt):\n",
    "    return int(str(dt).split(\" \")[0])\n",
    "conv_to_int = np.vectorize(conv_delta_to_int)\n",
    "\n",
    "t = conv_to_int(pd.to_datetime(jhu.columns[first_day_column:]) - first_day) # current time stamps\n",
    "t_ = np.arange(250) # time stamps with further range, used for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential(t, a,b):\n",
    "    return a*(np.exp(b*t))\n",
    "\n",
    "def logistic(t, c, a,b):\n",
    "    return c / (1. + a*np.exp(-1.0*b * t))\n",
    "\n",
    "def rectified(t,m,b, first_day):\n",
    "    def one_rect(t,m,b, first):\n",
    "        if m*t + b<1 and t<first_day:\n",
    "            return 1\n",
    "        else:\n",
    "            return m*t+b\n",
    "    rect = np.vectorize(one_rect)\n",
    "    return rect(t,m,b,first_day)\n",
    "    \n",
    "\n",
    "def before_sign(x):\n",
    "    if x <0:\n",
    "        return -1\n",
    "    if x>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def after_sign(x):\n",
    "    if x >0:\n",
    "        return -1\n",
    "    if x<0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "before_vect = np.vectorize(before_sign)\n",
    "after_vect = np.vectorize(after_sign)\n",
    "\n",
    "def get_all_inflections(vals, window_size = 25, base_jump = 5, peak_decline = 10):\n",
    "    peak_inf = 0\n",
    "    max_peak = 0\n",
    "    case_der = np.diff(vals,2)\n",
    "    base_test = np.absolute(case_der) > base_jump\n",
    "    if len([i for i, x in enumerate(base_test) if x]) ==0:\n",
    "        return None, None\n",
    "    else:\n",
    "        base_inf = [i for i, x in enumerate(base_test) if x][0]\n",
    "    test = case_der <-peak_decline\n",
    "    test2 = np.array([i for i, x in enumerate(test) if x]) >= decline_day\n",
    "    if len([i for i, x in enumerate(test2) if x]) < days_of_decline:\n",
    "        return None, base_inf\n",
    "    for idx, val in enumerate(case_der):\n",
    "        if idx ==0:\n",
    "            continue\n",
    "        if idx == len(case_der)-1:\n",
    "            continue\n",
    "        if idx <window_size:\n",
    "            if np.sum(before_vect(case_der[0:idx])) + np.sum(after_vect(case_der[idx+1:idx+1+window_size]))> max_peak:\n",
    "                peak_inf = idx\n",
    "                max_peak = np.sum(before_vect(case_der[0:idx])) + np.sum(after_vect(case_der[idx+1:idx+1+window_size]))\n",
    "        if idx >= window_size and idx < len(case_der)-window_size:\n",
    "            if np.sum(before_vect(case_der[idx-window_size:idx])) + np.sum(after_vect(case_der[idx+1:idx+1+window_size]))> max_peak:\n",
    "                peak_inf = idx\n",
    "                max_peak = np.sum(before_vect(case_der[idx-window_size:idx])) + np.sum(after_vect(case_der[idx+1:idx+1+window_size]))\n",
    "        if idx >=window_size and idx >= len(case_der)-window_size:\n",
    "            if np.sum(before_vect(case_der[idx-window_size:idx])) + np.sum(after_vect(case_der[idx+1:]))> max_peak:\n",
    "                peak_inf = idx\n",
    "                max_peak = np.sum(before_vect(case_der[idx-window_size:idx])) + np.sum(after_vect(case_der[idx+1:]))\n",
    "    return peak_inf, base_inf\n",
    "\n",
    "peak_dist = []\n",
    "for i, row in jhu.iterrows():\n",
    "    p, b = get_all_inflections(row[first_day_column:])\n",
    "    try:\n",
    "        peak_dist.append(np.absolute(p-b))\n",
    "    except:\n",
    "        continue\n",
    "avg_peak = int(np.round(np.average(peak_dist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_county(county_row, new_days = num_days, current_day = t[-1], val_size = val_set_size):\n",
    "    #print(county_row)\n",
    "    first = county_row['first_case_day']\n",
    "    peak, base = get_all_inflections(county_row[first_day_column:])\n",
    "    true_vals = np.array(county_row[first_day_column:].astype(int))\n",
    "    train_set = true_vals[:-val_size]\n",
    "    valid_set = true_vals[-val_size:]\n",
    "    \n",
    "    if base == None:\n",
    "        #print('rectified')\n",
    "        p0 = (1,-40)\n",
    "        bounds = ([0,-1500], [10,0])\n",
    "        f_rectified = lambda t_,a,b: rectified(t_,a,b,first)\n",
    "        (m,p),_ = opt.curve_fit(f_rectified,t[:-val_size],true_vals[:-val_size], bounds= bounds, p0 = p0)\n",
    "        predictions = [rectified(t,m,p,first) for t in t_[current_day+1:current_day+new_days+1]]\n",
    "        predictions = np.array(predictions).reshape(1,-1)[0]\n",
    "        pred_time = t_[current_day:current_day+new_days+1]\n",
    "        train_error = np.sum(np.square(np.log(train_set) - np.log([rectified(t,m,p,first) for t in t[:-val_size]])))\n",
    "        val_error = np.sum(np.square(np.log(valid_set) - np.log([rectified(t,m,p,first) for t in t[-val_size:]])))\n",
    "        if val_error>5:\n",
    "            predictions = np.full(len(predictions), train_set[-1])\n",
    "            val_error = np.sum(np.square(np.log(valid_set) - np.log(train_set[-1])))\n",
    "        \n",
    "        return predictions, pred_time, val_error\n",
    "        \n",
    "    if peak == None:\n",
    "        peak = base + avg_peak\n",
    "        if peak < current_day:\n",
    "            peak = current_day-1 \n",
    "    if current_day >= peak:\n",
    "        #print('logistic')\n",
    "        \n",
    "        final_c,final_a,final_b = 0,0,0\n",
    "        val_error_test = 1000000\n",
    "        for j in np.arange(epochs):\n",
    "            #p0 = (1000, 100, 0.3)\n",
    "            bounds = ([0,0,0], [10000000, 100000000, 3])\n",
    "            (c,a,b),_ = opt.curve_fit(logistic,t[:-val_size],true_vals[:-val_size], bounds = bounds)\n",
    "            train_error = np.sum(np.square(np.log(true_vals[np.nonzero(train_set)]) - np.log([logistic(t,c,a,b) for t in t[np.nonzero(train_set)]])))\n",
    "            val_error = np.sum(np.square(np.log(valid_set) - np.log([logistic(t,c,a,b) for t in t[-val_size:]])))\n",
    "            if val_error < val_error_test:\n",
    "                final_c, final_a,final_b = c,a,b\n",
    "                val_error_test = val_error\n",
    "        predictions = [logistic(t,final_c,final_a,final_b) for t in t_[current_day+1:current_day+new_days+1]]\n",
    "        pred_time = t_[current_day+1:current_day+new_days+1]\n",
    "    elif current_day< peak: #and current_day  + new_days <= peak:\n",
    "        #print('exponential')\n",
    "        final_a,final_b = 0,0\n",
    "        val_error_test = 1000000\n",
    "        for j in np.arange(epochs):\n",
    "            p0 = (1,.5)\n",
    "            bounds = ([0.01,0], [10,1])\n",
    "            (a,b),_ = opt.curve_fit(exponential,t[:-val_size],true_vals[:-val_size], bounds = bounds, p0=p0)\n",
    "            train_error = np.sum(np.square(np.log(true_vals[np.nonzero(train_set)]) - np.log([exponential(t,a,b) for t in t[np.nonzero(train_set)]])))\n",
    "            val_error = np.sum(np.square(np.log(valid_set) - np.log([exponential(t,a,b) for t in t[-val_size:]])))\n",
    "            if val_error < val_error_test:\n",
    "                final_a, final_b = a,b\n",
    "                val_error_test = val_error\n",
    "        predictions = [exponential(t,final_a,final_b) for t in t_[current_day+1:current_day+new_days+1]]\n",
    "        pred_time = t_[current_day+1:current_day+new_days+1]\n",
    "    '''elif current_day< peak and current_day  + new_days >= peak:\n",
    "        # piecewise prediction\n",
    "        print('piecewise')\n",
    "        final__a,final__b = 0,0\n",
    "        val_error_test = 1000000\n",
    "        for j in np.arange(epochs):\n",
    "            p0 = (1,.5)\n",
    "            bounds = ([0.01,0], [10,1])\n",
    "            (a,b),_ = opt.curve_fit(exponential,t[:-val_size],true_vals[:-val_size], bounds = bounds, p0 =p0)\n",
    "            error = np.sum(np.square(np.log(true_vals[np.nonzero(true_vals)]) - np.log([exponential(t,a,b) for t in t[np.nonzero(true_vals)]])))\n",
    "            #val_error = np.sum(np.square(np.log(valid_set) - np.log([exponential(t,a,b) for t in t[-val_size:]])))\n",
    "            if error < val_error_test:\n",
    "                final__a, final__b = a,b\n",
    "                val_error_test = error\n",
    "        \n",
    "        predictions = [int(np.round(exponential(t,final__a,final__b))) for t in t_[current_day+1:peak+1]]\n",
    "        pred_time = t_[current_day+1:peak+1]\n",
    "        \n",
    "        true_pred_vals = np.concatenate((true_vals,predictions), axis=None)\n",
    "        final_c,final_a,final_b = 0,0,0\n",
    "        error_test = 100000\n",
    "        for j in np.arange(epochs):\n",
    "            #p0 = (1000, 100, 0.3)\n",
    "            bounds = ([0,0,0], [10000000, 1000000, 1])\n",
    "            \n",
    "            (c,a,b),_ = opt.curve_fit(logistic,t_[:len(true_pred_vals)],true_pred_vals, bounds = bounds)\n",
    "            error =  np.sum(np.square(np.log(true_pred_vals[np.nonzero(true_pred_vals)]) - np.log([logistic(t,c,a,b) for t in t_[np.nonzero(true_pred_vals)]])))\n",
    "            if error < error_test:\n",
    "                final_c, final_a,final_b = c,a,b\n",
    "                error_test = error\n",
    "        \n",
    "        predictions = np.concatenate((predictions,[logistic(t,final_c,final_a,final_b) for t in t_[peak+1:current_day+new_days+1]]), axis=None)\n",
    "        pred_time = np.concatenate((pred_time, t_[peak+1:current_day+new_days+1]), axis = None)'''\n",
    "        \n",
    "    return predictions, pred_time, val_error_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df = jhu, current_day = t[-1], new_days = num_days):\n",
    "    prediction_array = t_[current_day+1:current_day+new_days+1]\n",
    "    prediction_df = pd.DataFrame()\n",
    "    prediction_df['State'] = df['Province_State']\n",
    "    prediction_df['County'] = df['Admin2']\n",
    "    val_errors = []\n",
    "    for i, row in jhu.iterrows():\n",
    "        try:\n",
    "            predictions, time, val_error = pred_county(row)\n",
    "            prediction_array = np.vstack((prediction_array, predictions))\n",
    "            val_errors.append(val_error)\n",
    "                \n",
    "        except:\n",
    "            print('error', i)\n",
    "        \n",
    "    def conv_int_to_delta(day):\n",
    "        return first_day + timedelta(days = int(day))\n",
    "    conv_to_delta = np.vectorize(conv_int_to_delta)\n",
    "    pred_df = pd.DataFrame(data = prediction_array[1:,:], columns = conv_to_delta(prediction_array[0,:]))\n",
    "    predictions_df = pd.concat([prediction_df, pred_df], axis=1)\n",
    "    full_df = pd.concat([jhu,pred_df], axis = 1)\n",
    "    \n",
    "    return predictions_df,full_df, val_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 1380\n",
      "Validation error average:  0.5115027456686246\n"
     ]
    }
   ],
   "source": [
    "predictions, full_df, validation_errors = predict()\n",
    "print('Validation error average: ', np.average(validation_errors ))\n",
    "predictions.to_csv(prediction_file_name)\n",
    "full_df.to_csv(jhu_and_prediciton_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
